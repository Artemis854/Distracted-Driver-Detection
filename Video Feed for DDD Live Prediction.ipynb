{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhqEtGLlyhmt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "TRAIN_DATADIR = '/home/kaushal/Datasets/DistractedDriverDetectionData/train/'\n",
    "TEST_DATADIR = '/home/kaushal/Datasets/DistractedDriverDetectionData/test/'\n",
    "TRAIN_DATA_NPY = './npy_arrays/train_data.npy'\n",
    "TRAIN_DATA_COLOR_NPY = './npy_arrays/train_color_data.npy'\n",
    "TEST_DATA_NPY = './npy_arrays/test_data.npy'\n",
    "TEST_UNKNOWN = './datasets/testunknown'\n",
    "\n",
    "# Categorical information\n",
    "CATEGORIES = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "IMG_CATEGORIES = ['Safe Driving',\n",
    "  'Texting Right' ,\n",
    "  'Talking Right' , \n",
    "  'Texting Left ' ,\n",
    "  'Talking Left ' ,\n",
    "  'Adjust Radio/Music Player' , \n",
    "  'Drinking',\n",
    "  'Reaching Behind', \n",
    "  'Hair and Makeup' , \n",
    "  'Talking to Passenger']\n",
    "\n",
    "# Model information\n",
    "IMG_SIZE = 128\n",
    "LR = 1e-3\n",
    "MODEL_NAME = 'Distracted_Driver_CNN' \n",
    "\n",
    "# Prediction setup\n",
    "model = load_model('./assets/DDD.model/')\n",
    "cv2Font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "prediction_queue = []\n",
    "current_prediction = 'Safe Driving'\n",
    "alert = False\n",
    "\n",
    "def getArea(x, y, w, h):\n",
    "    return (x+w) * (y+h)\n",
    "\n",
    "def toString(n):\n",
    "    return str(n)\n",
    "\n",
    "def prepare(frame):\n",
    "    img_array = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "#     plt.imshow(img_array, cmap=\"gray\")\n",
    "#     plt.show()\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)/255.0  # return the image with shaping that TF wants.\n",
    "\n",
    "def add_to_prediction_queue(prediction):\n",
    "    global current_prediction\n",
    "    global alert\n",
    "    \n",
    "    category = np.argmax(prediction)\n",
    "    if len(prediction_queue) >= 10:\n",
    "        prediction_queue.pop(0)\n",
    "    \n",
    "#     print(\"Prediction:\", prediction[category], IMG_CATEGORIES[category])\n",
    "    \n",
    "    if prediction[category] > 0.6:\n",
    "        prediction_queue.append(category)\n",
    "        current_prediction = toString(IMG_CATEGORIES[category])\n",
    "    else:\n",
    "        prediction_queue.append(0)\n",
    "        current_prediction = toString(IMG_CATEGORIES[0])\n",
    "        \n",
    "#     print(\"Prediction Queue:\", prediction_queue)\n",
    "    \n",
    "    if prediction_queue.count(0) < 4:\n",
    "        alert = True\n",
    "    else:\n",
    "        alert = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQynCVQFyjMp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reaching_behindVideo Captured!\n",
      "talking_leftVideo Captured!\n",
      "safe_drivingVideo Captured!\n",
      "talking_passengerVideo Captured!\n",
      "texting_rightVideo Captured!\n",
      "talking_rightVideo Captured!\n"
     ]
    }
   ],
   "source": [
    "files = ['reaching_behind', 'talking_left', 'safe_driving', 'talking_passenger', 'texting_right', 'talking_right']\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    # capture frames from a video\n",
    "    vc = cv2.VideoCapture('./assets/raw_video/' + file + '.mp4')\n",
    "    frame_array = []\n",
    "    if vc.isOpened():\n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "\n",
    "    # loop runs if new frame exists\n",
    "    while rval:\n",
    "        # read frame from a video\n",
    "        rval, frame = vc.read()\n",
    "        if not rval:\n",
    "            continue\n",
    "\n",
    "        height, width, layers = frame.shape\n",
    "        size = (width,height)\n",
    "\n",
    "        image = prepare(frame)\n",
    "        prediction = model.predict([image])\n",
    "\n",
    "        add_to_prediction_queue(prediction[0])\n",
    "\n",
    "    #     print(\"Prediction:\", IMG_CATEGORIES[np.argmax(prediction)])\n",
    "\n",
    "        cv2.putText(frame, current_prediction, (50,50), cv2Font, 0.9, (0, 0, 255), 2)\n",
    "    #     print(\"Current Prediction:\", current_prediction)\n",
    "\n",
    "        if alert == True:\n",
    "            cv2.putText(frame, \"ALERT\", (450,50), cv2Font, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        # Display frames in a window\n",
    "    #     cv2.namedWindow('feed', cv2.WINDOW_NORMAL)\n",
    "    #     cv2.resizeWindow('feed', 1280, 750)\n",
    "    #     cv2.imshow('feed', frame)\n",
    "\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(frame)\n",
    "\n",
    "        out = cv2.VideoWriter('./assets/processed_videos/' + file + '_output.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 30, size)\n",
    "\n",
    "        # Wait for Esc key to stop\n",
    "        if cv2.waitKey(33) == 27:\n",
    "            break\n",
    "\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()\n",
    "\n",
    "    print(file + \"Video Captured!\")\n",
    "    # De-allocate any associated memory usage\n",
    "    cv2.destroyAllWindows()\n",
    "    vc.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Predicting from Test Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Distracted-Driver-Detection",
   "language": "python",
   "name": "distracted-driver-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
